"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const schema_1 = require("@ulixee/schema");
const TypeSerializer_1 = require("@ulixee/commons/lib/TypeSerializer");
const addGlobalInstance_1 = require("@ulixee/commons/lib/addGlobalInstance");
const moment = require("moment");
const Extractor_1 = require("./Extractor");
const Table_1 = require("./Table");
class Crawler extends Extractor_1.default {
    constructor(components, ...plugins) {
        super({ ...components }, ...plugins);
        this.extractorType = 'crawler';
        this.components.run = this.runWrapper.bind(this, this.components.run);
        this.crawlerComponents = this.components;
    }
    attachToDatastore(datastoreInternal, extractorName) {
        super.attachToDatastore(datastoreInternal, extractorName);
        if (!this.crawlerComponents.disableCache) {
            const isBackwardsCompatible = this.crawlerComponents.backwardsCompatible ?? false;
            this.cache = new Table_1.default({
                isPublic: false,
                name: `crawler_cache_${extractorName}`,
                schema: {
                    input: (0, schema_1.string)({ description: 'TypeSerialized json of the inputs' }),
                    sessionId: (0, schema_1.string)({
                        description: 'The scraper specific session id generated by toCrawlerOutput.',
                    }),
                    crawler: (0, schema_1.string)(),
                    version: (0, schema_1.string)({ description: 'The crawler version.' }),
                    runTime: (0, schema_1.date)({ past: true, description: 'The time this session was run.' }),
                },
                async onVersionMigrated(previousVersion) {
                    if (isBackwardsCompatible) {
                        await this.insertInternal(...(await previousVersion.fetchInternal()));
                    }
                },
            });
            datastoreInternal.attachTable(this.cache);
        }
    }
    async runWrapper(originalRun, context) {
        const { outputs: _o, Output, datastoreMetadata: _d, input, schema, onCacheUpdated, ...rest } = context;
        const cached = await this.findCached(input);
        if (cached) {
            Output.emit(cached);
            return;
        }
        const result = await originalRun({ input, schema, ...rest });
        const output = await result.toCrawlerOutput();
        await this.saveToCache(input, output, onCacheUpdated);
        Output.emit(output);
    }
    async saveToCache(input, output, onCacheUpdated) {
        if (this.crawlerComponents.disableCache || !output.sessionId)
            return {};
        const serializedInput = this.getSerializedInput(input);
        const previousResult = await this.cache.queryInternal('DELETE FROM self WHERE input=$1 RETURNING sessionId', [serializedInput]);
        const deletedSessionId = previousResult?.[0]?.sessionId;
        if (onCacheUpdated && deletedSessionId) {
            await onCacheUpdated(deletedSessionId, output.crawler, 'evicted');
        }
        const data = {
            input: serializedInput,
            ...output,
            runTime: new Date(),
        };
        const fields = Object.keys(data);
        const fieldKeys = fields.map((_, i) => `$${i + 1}`);
        await this.cache.queryInternal(`INSERT INTO self (${fields.join(', ')}) VALUES (${fieldKeys.join(', ')})`, Object.values(data));
        if (onCacheUpdated) {
            await onCacheUpdated(output.sessionId, output.crawler, 'cached');
        }
    }
    async findCached(input) {
        if (this.crawlerComponents.disableCache)
            return null;
        input.maxTimeInCache ??= Crawler.defaultMaxTimeInCache;
        const maxAge = moment().add(-input.maxTimeInCache, 'seconds').toISOString();
        const serializedInput = this.getSerializedInput(input);
        const cached = await this.cache.queryInternal(`SELECT * FROM self WHERE runTime >= $1 AND input=$2 LIMIT 1`, [maxAge, serializedInput]);
        if (cached.length) {
            const [{ sessionId, version, crawler }] = cached;
            return { sessionId, version, crawler };
        }
        return null;
    }
    getSerializedInput(input) {
        const { maxTimeInCache: _m, sessionId: _s, ...inputArgs } = input;
        return TypeSerializer_1.default.stringify(inputArgs, { sortKeys: true });
    }
}
Crawler.defaultMaxTimeInCache = 10 * 60e3;
exports.default = Crawler;
(0, addGlobalInstance_1.default)(Crawler);
// eslint-disable-next-line @typescript-eslint/no-unused-vars
const CrawlerInputSchema = {
    maxTimeInCache: (0, schema_1.number)({
        min: 0,
        integer: true,
        optional: true,
        description: 'The maximum age in seconds of a cached web session.',
    }),
};
//# sourceMappingURL=Crawler.js.map